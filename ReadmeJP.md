最初に、LLMとツールの連携の仕組みについて説明します。多くのLLM、特にGPT-4やGeminiのような最新のモデルは、「関数呼び出し（Function Calling）」 または 「ツール呼び出し（Tool Calling）」 と呼ばれる機能に対応しています。この機能は以下のような仕組みで動作します。
- n8nのAIエージェントノードでは、SerpApiなどのツールノードを接続することで、そのツールの機能（例: Google Search）と、必要な引数（例: query）をLLMに伝えることから始めます。<br>
- まず、n8nノードは、ユーザーの入力（例: 今の気温を知りたい）と、上記で定義したツール情報をLLMに送信します。LLMはプロンプトを分析し、「これは外部検索が必要な質問だ」と判断します。<br>
- 次に、LLMは直接的な回答を生成するのではなく、「Google Searchというツールをqueryに今の気温という引数で呼び出す」 という形式の特殊なJSONデータやテキストを生成します。<br>
- その後、n8nのAIエージェントノードはLLMから返されたこのJSONを解釈し、LLMが「ツールを呼び出すべき」と判断したと認識し、AIエージェントノードは指定されたツール（SerpApi）と引数（query: '今の気温'）を使って、実際にGoogle検索を実行します。<br>
- Google検索の結果が取得されると、n8nノードはその結果を再びLLMに送ります。<br>
- 最終的に、LLMは提供された検索結果を基に、ユーザーにとって自然で分かりやすい最終的な回答（例: 現在の東京の気温は〇〇度です。）を生成します。<br>

なお、LLMが「ツールを呼び出すべき」と判断する過程は、一見すると曖昧なプロセスのように感じますが、そうではなく、モデルの訓練データと、Tool Calling機能の設計に基づいた論理的な推論プロセスです。これは、LLMが単語の確率論的予測を行うだけでなく、複雑なタスクを分解し、どのツールがそのタスクを解決するために最も適しているかを判断する能力を持っているためです。<br>
もう少し詳しく説明すると、n8nのノードは、LLMにユーザーの入力だけでなく、利用可能なツールの機能（例: Google Search、image_generatorなど）と、それらがどのような目的で使われるべきかの説明を同時に渡します。この情報が、LLMの推論をガイドする「明確なルールセット」となります。例えば、Google Searchツールには「最新の情報、リアルタイムデータ、ウェブサイトのコンテンツを検索するために使ってください」といった説明が付与されます。<br>
これに加え、GPTやGeminiのような最新のLLMは、大量のデータセットで訓練されており、その中には「外部の情報源を参照して質問に答える」というパターンも含まれています。これにより、モデルは「今日の天気は？」といった質問が、単なる知識ではなく、外部ツールを必要とするタスクであることを学習しています。同時に、LLMは、ユーザーのプロンプトの「意図」を分析します。例えば、今日の天気であれば、意図として最新のリアルタイム情報が求められていると分析します。また、日本の首都はどこ？という質問であれば、それは既知の知識で回答可能と判断できます。このプロセスは、まるで人間が「今日の天気は？」と聞かれたときに、頭の中の知識だけで答えず、スマホで天気予報を調べるように、LLMがタスクの性質を理解し、適切なツール（スマホ）を選択するのと似ています。<br>
LLMの判断は確率的なものですが、その確率の背後には、ツール呼び出しが最も合理的で効率的な解決策であるという強い根拠が存在します。したがって、これは単なる「曖昧な推測」ではなく、明確な意図に基づく「論理的な判断」となっています。
